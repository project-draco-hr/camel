{
  int messageInTopic=10;
  int messageInOtherTopic=5;
  CountDownLatch messagesLatch=new CountDownLatch(messageInTopic + messageInOtherTopic);
  Map<String,Object> inTopicHeaders=new HashMap<String,Object>();
  inTopicHeaders.put(KafkaConstants.PARTITION_KEY,"1".getBytes());
  sendMessagesInRoute(messageInTopic,bytesTemplate,"IT test message".getBytes(),inTopicHeaders);
  Map<String,Object> otherTopicHeaders=new HashMap<String,Object>();
  otherTopicHeaders.put(KafkaConstants.PARTITION_KEY,"1".getBytes());
  otherTopicHeaders.put(KafkaConstants.TOPIC,TOPIC_BYTES_IN_HEADER);
  sendMessagesInRoute(messageInOtherTopic,bytesTemplate,"IT test message in other topic".getBytes(),otherTopicHeaders);
  createKafkaBytesMessageConsumer(bytesConsumerConn,TOPIC_BYTES,TOPIC_BYTES_IN_HEADER,messagesLatch);
  boolean allMessagesReceived=messagesLatch.await(200,TimeUnit.MILLISECONDS);
  assertTrue("Not all messages were published to the kafka topics. Not received: " + messagesLatch.getCount(),allMessagesReceived);
  List<Exchange> exchangeList=mockEndpoint.getExchanges();
  assertEquals("Fifteen Exchanges are expected",exchangeList.size(),15);
  for (  Exchange exchange : exchangeList) {
    @SuppressWarnings("unchecked") List<RecordMetadata> recordMetaData1=(List<RecordMetadata>)(exchange.getIn().getHeader(KafkaConstants.KAFKA_RECORDMETA));
    assertEquals("One RecordMetadata is expected.",recordMetaData1.size(),1);
    assertTrue("Offset is positive",recordMetaData1.get(0).offset() >= 0);
    assertTrue("Topic Name start with 'test'",recordMetaData1.get(0).topic().startsWith("test"));
  }
}
